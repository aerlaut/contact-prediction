{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530a77b-3fc2-40b7-b754-e770fb3964e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific libs\n",
    "from datetime import datetime\n",
    "\n",
    "# scientific libs\n",
    "import numpy as np\n",
    "\n",
    "# DL libs\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import esm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from esm.data import ESMStructuralSplitDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# graph libs\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9a050-ff73-4d7f-9f5c-f1058d46bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adapted from: https://github.com/facebookresearch/esm/blob/main/examples/esm_structural_dataset.ipynb\"\"\"\n",
    "\n",
    "data_path = \"./data/esm\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ESMStructuralSplitDataset(\n",
    "    split_level='superfamily',\n",
    "    cv_partition='4',\n",
    "    split='train',\n",
    "    root_path = data_path\n",
    ")\n",
    "\n",
    "valid_dataset = ESMStructuralSplitDataset(\n",
    "    split_level='superfamily',\n",
    "    cv_partition='4',\n",
    "    split='valid',\n",
    "    root_path = data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879bd1e-9b8c-4194-b40d-a895afacc27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "# model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters of the pretrained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e50f67-3054-46fa-bc15-4f14899921d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data, optimizer, and objective/loss function\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "contact_threshold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138cd86c-28de-4270-b2bc-3e8386e19577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code below to get exampes of output\n",
    "rand_example = np.random.randint(len(valid_dataset))\n",
    "rand_target = valid_dataset[rand_example]\n",
    "print(f\"Data point {rand_example}, {rand_target['seq']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c85b7d-a675-4bee-ad1c-29a6dacf2722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixed example to compare\n",
    "rand_example = 229\n",
    "rand_target = valid_dataset[rand_example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e15c68-2805-40a3-a62e-88b67bf023c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_labels, batch_strs, batch_tokens = batch_converter([(rand_example, rand_target[\"seq\"])])\n",
    "rand_target_c = rand_target['dist'] < contact_threshold\n",
    "\n",
    "outputs = model(batch_tokens, return_contacts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab131dd0-07e0-491c-98b8-c0b0c67ccf92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = len(batch_strs[0])\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "im = ax[0].imshow(outputs['contacts'][0].detach().numpy() > 0.5)\n",
    "fig.colorbar(im)\n",
    "ax[0].set_title(\"Predicted\")\n",
    "im = ax[1].imshow(rand_target_c) #['dist'] < contact_threshold)\n",
    "fig.colorbar(im)\n",
    "ax[1].set_title(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f55377-b223-4302-bd6b-389812eb74fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify only the last layer for regression task\n",
    "model.contact_head.regression = nn.Linear(in_features=model.contact_head.regression.in_features, out_features=1)\n",
    "\n",
    "# Set requires_grad=True only for the regression layer parameters to be trained\n",
    "for param in model.contact_head.regression.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e05bf-a0a2-4ab2-992a-7bae8410953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the nans\n",
    "masked_train = []\n",
    "masked_valid = []\n",
    "\n",
    "# modify dataset to remove/mask entries without any coordinates/distances\n",
    "for data in train_dataset:\n",
    "    mask = ~np.isnan(data[\"coords\"].sum(axis=1))\n",
    "    mdist = data[\"dist\"][mask][:, mask]\n",
    "    masked_entry = {\n",
    "        \"seq\": \"\".join(c for c, cm in zip(data['seq'], mask) if cm),\n",
    "        \"ssp\": \"\".join(c for c, cm in zip(data['ssp'], mask) if cm),\n",
    "        \"coords\": data[\"coords\"][mask],\n",
    "        # Boolean values to only recognise distances up to a threshold of 15A\n",
    "        \"dist\": mdist < contact_threshold\n",
    "    }\n",
    "    masked_train.append(masked_entry)\n",
    "\n",
    "for data in valid_dataset:\n",
    "    mask = ~np.isnan(data[\"coords\"].sum(axis=1))\n",
    "    mdist = data[\"dist\"][mask][:, mask]\n",
    "    masked_entry = {\n",
    "        \"seq\": ''.join(c for c, cm in zip(data[\"seq\"], mask) if cm),\n",
    "        \"ssp\": ''.join(c for c, cm in zip(data[\"ssp\"], mask) if cm),\n",
    "        \"coords\": data[\"coords\"][mask],\n",
    "        \"dist\": mdist < contact_threshold\n",
    "    }\n",
    "    masked_valid.append(masked_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4931de-75e4-4c34-9eef-e9e92cf6a089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.cuda.is_built():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model and tensors to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run name\n",
    "run_name = \"finetune_esm2_t6_8M_UR50D_4-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_writer = SummaryWriter(log_dir=f\"./runs/{run_name}\")\n",
    "\n",
    "def memory_usage():\n",
    "    return torch.mps.current_allocated_memory() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058e2a4-0f00-4a72-a5b0-a9c86b1bf728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "learning_rate = 0.003\n",
    "batch_size = 1024\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "# Create an optimizer object\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "# loss is calculated for each input and target pair, mean values calculated manually\n",
    "loss_fn_none = nn.BCELoss(reduction=\"none\").to(device)\n",
    "loss_fn_mean = nn.BCELoss(reduction=\"mean\").to(device)\n",
    "\n",
    "print(f\"Epoch\\tTrain loss\\tTest loss\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Initialise losses\n",
    "    total_loss = 0\n",
    "    valid_loss = 0\n",
    "    validation_size = 1\n",
    "\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Training on randomly selected sequences in batches of 8\n",
    "    for b in tqdm(\n",
    "        DataLoader(\n",
    "            np.random.choice(\n",
    "                len(masked_train),\n",
    "                size=batch_size,\n",
    "                replace=False\n",
    "            ),\n",
    "            batch_size=8,\n",
    "            shuffle=True\n",
    "        ), ncols=40):\n",
    "        # Tokenise input sequences\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter([(i, masked_train[i][\"seq\"]) for i in b])\n",
    "\n",
    "        # Clear gradients for each epoch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Output predictions for batch\n",
    "        outputs = model(batch_tokens.to(device), return_contacts=True)\n",
    "\n",
    "        # Initialise objects to 0 to match the format of contact output tensor\n",
    "        targets = torch.zeros_like(outputs[\"contacts\"])\n",
    "        mask = torch.zeros_like(outputs[\"contacts\"])\n",
    "        src_mask = torch.zeros_like(outputs[\"contacts\"])\n",
    "\n",
    "        # Pull masked and boolean (dist threshold) values from training sequences\n",
    "        for i_, ti in enumerate(b):\n",
    "            cm = masked_train[ti][\"dist\"]\n",
    "            N = cm.shape[0]\n",
    "            targets[i_, :N, :N] = torch.tensor(cm)\n",
    "            mask[i_, :N, :N] = 1\n",
    "            # Short range contacts up to 12 redidues are masked\n",
    "            row_up, col_up = torch.triu_indices(N, N, offset=12)\n",
    "            row_low, col_low = torch.tril_indices(N, N, offset=-12)\n",
    "            src_mask[i_, row_up, col_up] = 1\n",
    "            src_mask[i_, row_low, col_low] = 1\n",
    "            targets = targets * src_mask\n",
    "\n",
    "        del src_mask\n",
    "\n",
    "        # Calculates bce loss between predictions and true values\n",
    "        loss = loss_fn_none(outputs[\"contacts\"], targets.to(device))\n",
    "\n",
    "        del targets, outputs\n",
    "\n",
    "        # Manually calculate mean per run (reduction = \"none\")\n",
    "        loss = (loss * mask).mean()\n",
    "\n",
    "        del mask\n",
    "\n",
    "        # Pool loss values from each batch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates last layer parameters to reduce loss\n",
    "        optimizer.step()\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for b in DataLoader(range(validation_size), batch_size=1, shuffle=True):\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter([(i, masked_valid[i][\"seq\"]) for i in b])\n",
    "\n",
    "        # contacts\n",
    "        outputs = model(batch_tokens.to(device), return_contacts=True)\n",
    "\n",
    "        del batch_tokens\n",
    "\n",
    "        # Calculates loss between predictions and true values\n",
    "        targets = torch.tensor(np.array([masked_valid[i][\"dist\"] for i in b]), dtype=torch.float32).to(device)\n",
    "        loss = loss_fn_mean(outputs[\"contacts\"], targets)\n",
    "\n",
    "        del targets\n",
    "\n",
    "        # Pool loss values from each batch\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    # Print loss per epoch\n",
    "    average_loss = total_loss / batch_size\n",
    "    average_loss_test = valid_loss / validation_size\n",
    "\n",
    "    # Write to Tensorboard logs\n",
    "    tb_writer.add_scalar(\"Loss/train\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Loss/test\", average_loss_test, epoch)\n",
    "    tb_writer.add_scalar(\"Memory usage (GB)\", memory_usage(), epoch)\n",
    "\n",
    "    print(f\"{epoch+1}/{num_epochs}\\t{average_loss:.4f}\\t\\t{average_loss_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d35cf8-d86c-44f0-9550-6f7176ac7709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_labels, batch_strs, batch_tokens = batch_converter([(rand_example, rand_target[\"seq\"])])\n",
    "rand_target_c = rand_target['dist'] < contact_threshold\n",
    "\n",
    "outputs = model(batch_tokens.to(device), return_contacts=True)\n",
    "\n",
    "N = len(batch_strs[0])\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "im = ax[0].imshow(outputs['contacts'][0].to('cpu').detach().numpy() > 0.5)\n",
    "fig.colorbar(im)\n",
    "ax[0].set_title(\"Predicted\")\n",
    "im = ax[1].imshow(rand_target_c)\n",
    "fig.colorbar(im)\n",
    "ax[1].set_title(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63af53-09c4-4c21-ba1a-a99b77588904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random example testing\n",
    "rand_example = np.random.randint(len(valid_dataset))\n",
    "rand_target = valid_dataset[rand_example]\n",
    "\n",
    "print(f\"Data point {rand_example}, {rand_target['seq']}\")\n",
    "\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter([(rand_example, rand_target[\"seq\"])])\n",
    "rand_target_c = rand_target['dist'] < contact_threshold\n",
    "\n",
    "outputs = model(batch_tokens, return_contacts=True)\n",
    "\n",
    "N = len(batch_strs[0])\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 3))\n",
    "im = ax[0].imshow(outputs['contacts'][0].detach().numpy() > 0.5)\n",
    "fig.colorbar(im)\n",
    "ax[0].set_title(\"Predicted\")\n",
    "im = ax[1].imshow(rand_target_c)\n",
    "fig.colorbar(im)\n",
    "ax[1].set_title(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a05b2ff-a013-4b3d-8cd1-7969a1d94544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(model, 'trained_model_1024_BCE_6ep.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
